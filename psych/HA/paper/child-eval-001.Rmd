
## model evaluations
### covariances
```{r eval_001_cov,eval=TRUE,warning=FALSE,echo=FALSE}
eff1<-vcov(eval.1$lme)
#eval.1$lme.form
eff1.s<-eff1
eff.ex<-eff1[grep("q",rownames(eff1)),]
eff1<-eff1[3:length(eff1[,1]),]
eff1<-eff1[!grepl("target",rownames(eff1)),]
e_plus_obs<-eff1[,1]>0
e_plus_ref<-eff1[,2]>0
#e_minus_obs<-eff1[,1]<0
#e_minus_ref<-eff1[,2]<0
e_sim<-e_plus_obs==e_plus_ref
e_sim_plus<-which(e_sim)[which(e_sim)%in%which(e_plus_obs)]
#e_sim_minus<-e_minus_obs==e_minus_ref
#which(e_sim_minus)
e_sim_w<-which(e_sim)
#e_sim_not<-which(!e_sim_plus)
e_sim_c<-paste0(rownames(eff1)[e_sim],collapse = ", ")
e_sim_c_plus_obs<-paste0(rownames(eff1)[e_sim_plus],collapse = ", ")
#e_sim_c_not<-paste0(rownames(eff1)[e_sim_not],collapse = ", ")
e_obs_minus<-paste0(rownames(eff1)[which(!e_sim)],collapse = ", ")
#e_ref_minus<-paste0(rownames(eff1)[which(!e_plus_ref)%in%which(e_sim_plus)],collapse = ", ")
#e_obs_minus

#e_ref_minus<-paste0(rownames(eff1)[!e_plus_ref],collapse = ", ")
#print(e_sim_c)
#eff1
# qs[[5]]$e$q
# paste0(c(paste0(qs[[2]]$b$q,collapse=","),paste0(qs[[5]]$e$q,collapse=","),paste0(qs[[6]]$f$q,collapse=",")),collapse = " - ")

#16422.todo: obs-ref estimate difference (tokens) in text!
#-1.220460e-01--1.123020e-01
#b <- fixef(eval.1$lmer)
#b
#eval.1$lme
#barplot(b)
```

Effects of the same direction for target OBS and REF are observed in ``` `r e_sim_c` ``` (with positive effects in ``` `r e_sim_c_plus_obs` ```) while contrary effects are observed in ``` `r e_obs_minus` ``` (with negative effects in target=obs and vcvs)  (cf. sec. \@ref(covar)).  

In words:   

- the antecedents ``` `r paste0(qs[[3]]$c$q,collapse=",")` ``` seem to allow a wider distance between referent and reference in both target=OBS and target=REF. 
- the antecedents ``` `r paste0(c(paste0(qs[[2]]$b$q,collapse=","),paste0(qs[[5]]$e$q,collapse=","),paste0(qs[[6]]$f$q,collapse=",")),collapse = " - ")` ``` decrease distance in target=OBS and increase distance values in target=REF; condition d (``` `r paste0(c(paste0(qs[[4]]$d$q,collapse=",")),collapse = " - ")` ```) vcvs.   
- higher ```embed.score``` values (better embedded noun) decrease distance in target=OBS and increase distance values in target=REF. (cf. par 3.7.5.4, better embedding allows wider distance > the expectation seems only valid for the reference corpus!)

***sidenote:*** Positing the url range only as fixed effect instead of normalising the distances still estimates smaller distances for the reference corpus, but with no significance, the only significant difference with that regression formula shows in target=REF under condition e (antecedents: ``` `r paste0(qs[[5]]$e$q,collapse=",")` ```).   

### model fazit
As you can cf. in the appendix with the seperate coefficient tables for each evaluation model, we find over all normalised subsets (vs. obs/ref/all) significantly smaller distances in the reference corpus with varying effects for the conditions. In the subsets, where we didnt normalise or remove outliers, we find the opposite effect; the raw data does not prove our hypothesis. But just looking into the (raw) mean values plot of Fig. \@ref(fig:barplot-mean2) we clearly see that normalising and removing outliers is necessary since mean distances there extend up to over 2000 tokens thus we wouldn't like to count all analogue noun occurences here as anaphora.






