{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4571cd06-c492-46a9-9330-3f3a44f727c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/smi312/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44239db0-24cd-4403-ab76-ec3f48d8a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d7aa97-0e99-49ea-a71a-f0da68c6f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_core_web_lg already installed.\n",
      "[('This', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "spacymodel = \"en_core_web_lg\"\n",
    "#import spacy\n",
    "spacymodel = \"en_core_web_lg\"\n",
    "# $ python -m spacy download en_core_web_lg\n",
    "\n",
    "#model = \"en_core_web_sm\"\n",
    "model = spacymodel\n",
    "try:\n",
    "    spacy.load(model)\n",
    "    print(f\"{model} already installed.\")\n",
    "except OSError:\n",
    "    print(f\"Downloading {model}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model])\n",
    "    nlp = spacy.load(model)\n",
    "    print(f\"{model} ready: {nlp.pipe_names}\")\n",
    "#print(sp.Default.stop_words)\n",
    "#nlp = spacy.load(model)\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "print([(w.text, w.pos_) for w in doc])\n",
    "\n",
    "model = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68000517-bc66-467e-9f9d-73008b900ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/guhl/boxHKW/UNIhkw/21S/DH/local\n",
      "/Users/guhl/boxHKW/UNIhkw/21S/DH/local/SPUND/2025/hux/DAIS-C-Annotated - Upload/DAI-C-CL/Speaker Only_Raw\n",
      "/Users/guhl/boxHKW/UNIhkw/21S/DH/local/SPUND/2025/hux/DAIS-C-Annotated - Upload/DAI-C-CO/Speaker Only_Raw\n"
     ]
    }
   ],
   "source": [
    "path_cl = \"/SPUND/2025/hux/DAIS-C-Annotated - Upload/DAI-C-CL/Speaker Only_Raw\"\n",
    "path_co = \"/SPUND/2025/hux/DAIS-C-Annotated - Upload/DAI-C-CO/Speaker Only_Raw\"\n",
    "path_clinical = \"DAIS-C-Annotated - Upload/DAI-C-CL/Speaker Only_Raw\"\n",
    "path_control = \"DAIS-C-Annotated - Upload/DAI-C-CO/Speaker Only_Raw\"\n",
    "#path_clinical = os.environ.get('HKW_TOP') + path_cl\n",
    "#path_control = os.environ.get('HKW_TOP') + path_co\n",
    "print(os.environ.get('HKW_TOP'))\n",
    "path_clinical = os.environ.get('HKW_TOP') + path_cl\n",
    "path_control = os.environ.get('HKW_TOP') + path_co\n",
    "print(path_clinical)\n",
    "print(path_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56742cd8-8d1a-4f46-8892-e8da2983a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect file names and their content\n",
    "data = []\n",
    "for filename in os.listdir(path_clinical):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(path_clinical, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        data.append({\"filename\": filename, \"text\": text})\n",
    "\n",
    "# Convert to DataFrame\n",
    "clinical = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5330a7-9e21-4a0c-8a9a-a01854b4a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect file names and their content\n",
    "data = []\n",
    "for filename in os.listdir(path_control):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(path_control, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        data.append({\"filename\": filename, \"text\": text})\n",
    "\n",
    "# Convert to DataFrame\n",
    "control = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d30a6b-006d-4fd3-b085-6a6a8e96e9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23EB14_Raw.txt</td>\n",
       "      <td>mhm yeah sometimes   I think \\n   \\n erm so I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28CT11_Raw.txt</td>\n",
       "      <td>erm yeah it was kind of weird   erm it was ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23OV14_Raw.txt</td>\n",
       "      <td>erm it was it was quite interesting erm yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16OV11_Raw.txt</td>\n",
       "      <td>erm different and it was quite interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19OV10_Raw.txt</td>\n",
       "      <td>well it sort of reminded me of the sort of te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02AR17_Raw.txt</td>\n",
       "      <td>I really enjoyed it erm I felt in parts frust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11AR18_Raw.txt</td>\n",
       "      <td>OK \\n erm that's a very open question isn't i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17AR13_Raw.txt</td>\n",
       "      <td>erm yes er I I you er oh I thought we were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26CT11_Raw.txt</td>\n",
       "      <td>it was really interesting it was fun   erm I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23CT19_Raw.txt</td>\n",
       "      <td>confusing   \\n but yeah it was fine it was go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16UN13_Raw.txt</td>\n",
       "      <td>do I feel like I use language creatively mm d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23CT18_Raw.txt</td>\n",
       "      <td>that's a very open question er it's good er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>09AR14_Raw.txt</td>\n",
       "      <td>oh OK \\n cool er   it was it was interesting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                               text\n",
       "0   23EB14_Raw.txt   mhm yeah sometimes   I think \\n   \\n erm so I...\n",
       "1   28CT11_Raw.txt   erm yeah it was kind of weird   erm it was ab...\n",
       "2   23OV14_Raw.txt     erm it was it was quite interesting erm yea...\n",
       "3   16OV11_Raw.txt      erm different and it was quite interesting...\n",
       "4   19OV10_Raw.txt   well it sort of reminded me of the sort of te...\n",
       "5   02AR17_Raw.txt   I really enjoyed it erm I felt in parts frust...\n",
       "6   11AR18_Raw.txt   OK \\n erm that's a very open question isn't i...\n",
       "7   17AR13_Raw.txt     erm yes er I I you er oh I thought we were ...\n",
       "8   26CT11_Raw.txt   it was really interesting it was fun   erm I ...\n",
       "9   23CT19_Raw.txt   confusing   \\n but yeah it was fine it was go...\n",
       "10  16UN13_Raw.txt   do I feel like I use language creatively mm d...\n",
       "11  23CT18_Raw.txt     that's a very open question er it's good er...\n",
       "12  09AR14_Raw.txt   oh OK \\n cool er   it was it was interesting ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3b87d3-2b02-4ed8-92c9-54a0d67c304a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21AP15_Raw.txt</td>\n",
       "      <td>do I do creative things with language y er er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12AY15_Raw.txt</td>\n",
       "      <td>er sometimes I would think more colourfully t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18UG14_Raw.txt</td>\n",
       "      <td>well I'm dyslexic so in text and stuff like t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18UG15_Raw.txt</td>\n",
       "      <td>erm I don't know it was erm annoying \\n yeah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26AR16_Raw.txt</td>\n",
       "      <td>OK OK \\n you know I  when I came to England a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22AP15_Raw.txt</td>\n",
       "      <td>OK yeah \\n yeah w so what university are you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21UN11_Raw.txt</td>\n",
       "      <td>do I feel like I use language creatively mm d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10EB15_Raw.txt</td>\n",
       "      <td>right erm er I'm er do I   do creative things...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10EB14_Raw.txt</td>\n",
       "      <td>can you repeat that \\n yes I do to some exten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03AR15_Raw.txt</td>\n",
       "      <td>OK \\n yeah \\n erm I suppose   it depends what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18UG09_Raw.txt</td>\n",
       "      <td>erm what do you mean by language \\n so yeah s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18UG10_Raw.txt</td>\n",
       "      <td>yeah I know \\n do I what sorry \\n in what way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WMatrix-full-clinical-raw.txt</td>\n",
       "      <td>OK \\n yeah \\n erm I suppose   it depends what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18UG11_Raw.txt</td>\n",
       "      <td>I'm intrigued to know what you want to know \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21AN11_Raw.txt</td>\n",
       "      <td>how do you mean language \\n well the only pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>03EB14_Raw.txt</td>\n",
       "      <td>I do erm   I I write song lyrics erm   poetry...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0                  21AP15_Raw.txt   \n",
       "1                  12AY15_Raw.txt   \n",
       "2                  18UG14_Raw.txt   \n",
       "3                  18UG15_Raw.txt   \n",
       "4                  26AR16_Raw.txt   \n",
       "5                  22AP15_Raw.txt   \n",
       "6                  21UN11_Raw.txt   \n",
       "7                  10EB15_Raw.txt   \n",
       "8                  10EB14_Raw.txt   \n",
       "9                  03AR15_Raw.txt   \n",
       "10                 18UG09_Raw.txt   \n",
       "11                 18UG10_Raw.txt   \n",
       "12  WMatrix-full-clinical-raw.txt   \n",
       "13                 18UG11_Raw.txt   \n",
       "14                 21AN11_Raw.txt   \n",
       "15                 03EB14_Raw.txt   \n",
       "\n",
       "                                                 text  \n",
       "0    do I do creative things with language y er er...  \n",
       "1    er sometimes I would think more colourfully t...  \n",
       "2    well I'm dyslexic so in text and stuff like t...  \n",
       "3    erm I don't know it was erm annoying \\n yeah ...  \n",
       "4    OK OK \\n you know I  when I came to England a...  \n",
       "5    OK yeah \\n yeah w so what university are you ...  \n",
       "6    do I feel like I use language creatively mm d...  \n",
       "7    right erm er I'm er do I   do creative things...  \n",
       "8    can you repeat that \\n yes I do to some exten...  \n",
       "9    OK \\n yeah \\n erm I suppose   it depends what...  \n",
       "10   erm what do you mean by language \\n so yeah s...  \n",
       "11   yeah I know \\n do I what sorry \\n in what way...  \n",
       "12   OK \\n yeah \\n erm I suppose   it depends what...  \n",
       "13   I'm intrigued to know what you want to know \\...  \n",
       "14   how do you mean language \\n well the only pro...  \n",
       "15   I do erm   I I write song lyrics erm   poetry...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46d12d4-38d1-44ce-9ad2-e7a8b2e62d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical[\"group\"] = \"scz\"\n",
    "control[\"group\"] = \"hc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f6e14d-bd37-4b5a-9117-85958805a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21AP15_Raw.txt</td>\n",
       "      <td>do I do creative things with language y er er...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12AY15_Raw.txt</td>\n",
       "      <td>er sometimes I would think more colourfully t...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18UG14_Raw.txt</td>\n",
       "      <td>well I'm dyslexic so in text and stuff like t...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18UG15_Raw.txt</td>\n",
       "      <td>erm I don't know it was erm annoying \\n yeah ...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26AR16_Raw.txt</td>\n",
       "      <td>OK OK \\n you know I  when I came to England a...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22AP15_Raw.txt</td>\n",
       "      <td>OK yeah \\n yeah w so what university are you ...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21UN11_Raw.txt</td>\n",
       "      <td>do I feel like I use language creatively mm d...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10EB15_Raw.txt</td>\n",
       "      <td>right erm er I'm er do I   do creative things...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10EB14_Raw.txt</td>\n",
       "      <td>can you repeat that \\n yes I do to some exten...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03AR15_Raw.txt</td>\n",
       "      <td>OK \\n yeah \\n erm I suppose   it depends what...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18UG09_Raw.txt</td>\n",
       "      <td>erm what do you mean by language \\n so yeah s...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18UG10_Raw.txt</td>\n",
       "      <td>yeah I know \\n do I what sorry \\n in what way...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WMatrix-full-clinical-raw.txt</td>\n",
       "      <td>OK \\n yeah \\n erm I suppose   it depends what...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18UG11_Raw.txt</td>\n",
       "      <td>I'm intrigued to know what you want to know \\...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21AN11_Raw.txt</td>\n",
       "      <td>how do you mean language \\n well the only pro...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>03EB14_Raw.txt</td>\n",
       "      <td>I do erm   I I write song lyrics erm   poetry...</td>\n",
       "      <td>scz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0                  21AP15_Raw.txt   \n",
       "1                  12AY15_Raw.txt   \n",
       "2                  18UG14_Raw.txt   \n",
       "3                  18UG15_Raw.txt   \n",
       "4                  26AR16_Raw.txt   \n",
       "5                  22AP15_Raw.txt   \n",
       "6                  21UN11_Raw.txt   \n",
       "7                  10EB15_Raw.txt   \n",
       "8                  10EB14_Raw.txt   \n",
       "9                  03AR15_Raw.txt   \n",
       "10                 18UG09_Raw.txt   \n",
       "11                 18UG10_Raw.txt   \n",
       "12  WMatrix-full-clinical-raw.txt   \n",
       "13                 18UG11_Raw.txt   \n",
       "14                 21AN11_Raw.txt   \n",
       "15                 03EB14_Raw.txt   \n",
       "\n",
       "                                                 text group  \n",
       "0    do I do creative things with language y er er...   scz  \n",
       "1    er sometimes I would think more colourfully t...   scz  \n",
       "2    well I'm dyslexic so in text and stuff like t...   scz  \n",
       "3    erm I don't know it was erm annoying \\n yeah ...   scz  \n",
       "4    OK OK \\n you know I  when I came to England a...   scz  \n",
       "5    OK yeah \\n yeah w so what university are you ...   scz  \n",
       "6    do I feel like I use language creatively mm d...   scz  \n",
       "7    right erm er I'm er do I   do creative things...   scz  \n",
       "8    can you repeat that \\n yes I do to some exten...   scz  \n",
       "9    OK \\n yeah \\n erm I suppose   it depends what...   scz  \n",
       "10   erm what do you mean by language \\n so yeah s...   scz  \n",
       "11   yeah I know \\n do I what sorry \\n in what way...   scz  \n",
       "12   OK \\n yeah \\n erm I suppose   it depends what...   scz  \n",
       "13   I'm intrigued to know what you want to know \\...   scz  \n",
       "14   how do you mean language \\n well the only pro...   scz  \n",
       "15   I do erm   I I write song lyrics erm   poetry...   scz  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1243a9a-8675-4f68-8f36-9d8e9626a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([clinical, control], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8338232-ef70-4690-8f57-45baba92c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"\\n\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95202cd1-2bbb-45ad-ae58-95da59109360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom stopwords\n",
    "custom_stops = {\"er\", \"erm\", \"oh\", \"yeah\", \"mm\", \"mhm\", \"y\"}\n",
    "\n",
    "for w in custom_stops:\n",
    "    model.Defaults.stop_words.add(w)\n",
    "    model.vocab[w].is_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547c788-33bb-4cf9-b41e-6f775bb196e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60781db-a24b-4a5d-9396-8529a19ab1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_tokens(text):\n",
    "    spacy_text = model(text)\n",
    "    list_of_tokens = [\n",
    "        token.text\n",
    "        for token in spacy_text\n",
    "        if (not token.is_punct)\n",
    "        and (not token.is_stop)\n",
    "        and token.text.strip()              # removes whitespace-only tokens\n",
    "    ]\n",
    "    return list_of_tokens\n",
    "\n",
    "def get_chunks(list_of_tokens):\n",
    "    chunks = [list_of_tokens[i:i+10] for i in range(0, len(list_of_tokens), 10)]\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a51fb-60e3-4e35-80ce-df252d1e7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cleaned_tokens(\"hello world how are you doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ed94a-57a0-4d4c-992a-31ae6fdf1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"list_tokens\"] = df[\"text\"].apply(get_cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b2e43-bdf7-45b2-b3f7-81f2b625edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5d431-7e1f-4b3f-b4bd-de836701699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"list_of_cunks\"] = df[\"list_tokens\"].apply(get_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3b0a2-8214-4c51-82a6-43d73c7c86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d20636-abe6-417f-bc2a-7c10b30a7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df.explode(\"list_of_cunks\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0746828-7b41-435a-a50d-3a324e15ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8189129-7c9e-4d95-82a1-24b58006cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.to_parquet(\"tabelle.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a080507-56a5-4d02-b99a-86856c4972e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae37b7-4b78-4e8c-81e0-1ce16c08eb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024969b9-f63d-4b85-af9a-b297134067e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413e94f-ddc5-40e7-8485-884c9fba3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1861c5-f3e1-4913-8a45-bb63c50ae30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef7425-3b0a-435d-a628-dfe98a2b5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in text:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63550f87-f83d-40cd-9e00-8911cc250fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bcf838-3a9d-4b2b-8294-d11ca05d158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [sent.text for sent in model(text).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf55b73-f9ae-4b8c-89d2-742b3576783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e9a15-a2b4-4f6b-b724-362bebb5711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "\n",
    "def build_nlp():\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1. Symptom onset expressions\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"SYMPTOM_ONSET\",\n",
    "        [\n",
    "            [{\"LOWER\": \"since\"}, {\"LOWER\": {\"IN\": [\"childhood\", \"infancy\", \"puberty\", \"teenage\", \"teens\"]}}],\n",
    "            [{\"LOWER\": \"since\"}, {\"LOWER\": \"i\"}, {\"LOWER\": \"was\"}, {\"IS_DIGIT\": True}],\n",
    "            [{\"LOWER\": \"back\"}, {\"LOWER\": \"in\"}, {\"LOWER\": {\"IN\": [\"college\", \"school\", \"university\", \"high\", \"uni\"]}}],\n",
    "            [{\"LOWER\": \"in\"}, {\"LOWER\": \"my\"}, {\"LOWER\": {\"IN\": [\"early\", \"mid\", \"late\"]}},\n",
    "             {\"LOWER\": {\"IN\": [\"teens\", \"twenties\", \"thirties\"]}}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 2. Episode-level markers\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"EPISODE_TEMPORAL\",\n",
    "        [\n",
    "            [{\"LOWER\": \"last\"}, {\"LOWER\": \"episode\"}, {\"LOWER\": \"in\"}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "            [{\"LOWER\": \"during\"}, {\"LOWER\": \"my\"},\n",
    "             {\"LOWER\": {\"IN\": [\"worst\", \"last\", \"previous\"]}},\n",
    "             {\"LOWER\": {\"IN\": [\"period\", \"episode\"]}}, {\"LOWER\": \"in\"}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 3. Treatment-related\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"TREATMENT_TEMPORAL\",\n",
    "        [\n",
    "            [{\"LOWER\": {\"IN\": [\"started\", \"began\", \"quit\", \"stopped\"]}},\n",
    "             {\"LOWER\": {\"IN\": [\"meds\", \"medications\", \"therapy\"]}},\n",
    "             {\"LOWER\": \"in\"}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "\n",
    "            [{\"LOWER\": {\"IN\": [\"hospitalised\", \"hospitalized\"]}},\n",
    "             {\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"years\", \"months\", \"weeks\"]}},\n",
    "             {\"LOWER\": \"ago\"}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 4. Relapse\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"RELAPSE_TEMPORAL\",\n",
    "        [\n",
    "            [{\"LOWER\": {\"IN\": [\"relapsed\", \"relapse\"]}},\n",
    "             {\"LOWER\": \"again\"}, {\"LOWER\": {\"IN\": [\"this\", \"last\"]}},\n",
    "             {\"LOWER\": {\"IN\": [\"year\", \"month\", \"week\"]}}],\n",
    "\n",
    "            [{\"LOWER\": {\"IN\": [\"episode\", \"episodes\"]}},\n",
    "             {\"LOWER\": \"last\"}, {\"LOWER\": {\"IN\": [\"month\", \"year\"]}}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 5. DURATIONS (corrected)\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"DURATION_TEMPORAL\",\n",
    "        [\n",
    "            # For six months / for months / for a year\n",
    "            [\n",
    "                {\"LOWER\": \"for\"},\n",
    "                {\"LOWER\": {\"IN\": [\"a\", \"an\"]}, \"OP\": \"?\"},\n",
    "                {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "                {\"LOWER\": {\"IN\": [\"day\", \"days\", \"week\", \"weeks\", \"month\",\n",
    "                                   \"months\", \"year\", \"years\", \"decade\"]}}\n",
    "            ],\n",
    "\n",
    "            # past few months\n",
    "            [\n",
    "                {\"LOWER\": \"past\"},\n",
    "                {\"LOWER\": {\"IN\": [\"few\", \"couple\", \"several\"]}},\n",
    "                {\"LOWER\": {\"IN\": [\"days\", \"weeks\", \"months\", \"years\"]}}\n",
    "            ]\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 6. Life-event anchors\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"LIFE_EVENT_TEMPORAL\",\n",
    "        [\n",
    "            [{\"LOWER\": {\"IN\": [\"after\", \"before\", \"around\", \"during\"]}},\n",
    "             {\"LOWER\": {\"IN\": [\"the\", \"my\"]}, \"OP\": \"?\"},\n",
    "             {\"LOWER\": {\"IN\": [\n",
    "                 \"divorce\", \"breakup\", \"accident\", \"pregnancy\", \"diagnosis\",\n",
    "                 \"hospitalisation\", \"hospitalization\", \"finals\", \"lockdown\"\n",
    "             ]}}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 7. Calendar markers\n",
    "    # -------------------------------------\n",
    "    seasons = [\"spring\", \"summer\", \"autumn\", \"fall\", \"winter\"]\n",
    "    holidays = [\"christmas\", \"easter\", \"ramadan\", \"new\", \"new-year\", \"new year\"]\n",
    "\n",
    "    matcher.add(\n",
    "        \"CALENDAR_TEMPORAL\",\n",
    "        [\n",
    "            [{\"LOWER\": {\"IN\": [\"this\", \"last\"]}}, {\"LOWER\": {\"IN\": seasons}}],\n",
    "            [{\"LOWER\": {\"IN\": [\"this\", \"last\"]}}, {\"LOWER\": {\"IN\": holidays}}],\n",
    "            [{\"LOWER\": {\"IN\": [\"earlier\", \"end\"]}}, {\"LOWER\": \"this\"},\n",
    "             {\"LOWER\": {\"IN\": [\"week\", \"month\", \"year\"]}}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 8. Vague expressions\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"VAGUE_TEMPORAL\",\n",
    "        [\n",
    "            [{\"LOWER\": \"a\"}, {\"LOWER\": \"while\"}, {\"LOWER\": \"ago\"}],\n",
    "            [{\"LOWER\": \"ages\"}, {\"LOWER\": \"ago\"}],\n",
    "            [{\"LOWER\": \"the\"}, {\"LOWER\": \"other\"}, {\"LOWER\": \"day\"}],\n",
    "            [{\"LOWER\": \"recently\"}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 9. Numeric date formats\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"NUMERIC_DATE\",\n",
    "        [\n",
    "            # 12/2020, 05/21\n",
    "            [{\"SHAPE\": \"dd\"}, {\"TEXT\": \"/\"}, {\"SHAPE\": {\"IN\": [\"dd\", \"dddd\"]}}],\n",
    "            # 12.05.2020\n",
    "            [{\"SHAPE\": \"dd\"}, {\"TEXT\": \".\"}, {\"SHAPE\": \"dd\"},\n",
    "             {\"TEXT\": \".\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\", \"OP\": \"?\"}],\n",
    "            # 2020–21, 2019/2020\n",
    "            [{\"SHAPE\": \"dddd\"}, {\"TEXT\": {\"IN\": [\"–\", \"-\", \"/\"]}}, {\"SHAPE\": {\"IN\": [\"dd\", \"dddd\"]}}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 10. Diagnosis + date\n",
    "    # -------------------------------------\n",
    "    matcher.add(\n",
    "        \"DIAGNOSIS_DATE\",\n",
    "        [\n",
    "            [{\"LOWER\": {\"IN\": [\"diagnosed\", \"dx\"]}}, {\"LOWER\": \"in\"}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "            [{\"LOWER\": {\"IN\": [\"diagnosed\", \"dx\"]}}, {\"IS_DIGIT\": True}],  # diagnosed at 14\n",
    "            [{\"LOWER\": {\"IN\": [\"got\", \"received\"]}}, {\"LOWER\": \"my\"},\n",
    "             {\"LOWER\": \"diagnosis\"}, {\"LOWER\": \"in\"}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    nlp.matcher = matcher\n",
    "    return nlp\n",
    "\n",
    "\n",
    "def extract_time_spans(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    spans = []\n",
    "\n",
    "    # built-in DATE entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            spans.append(ent.text)\n",
    "\n",
    "    # rule-based matches\n",
    "    for match_id, start, end in nlp.matcher(doc):\n",
    "        spans.append(doc[start:end].text)\n",
    "\n",
    "    # dedupe and preserve order\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for s in spans:\n",
    "        if s not in seen:\n",
    "            seen.add(s)\n",
    "            final.append(s)\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nlp = build_nlp()\n",
    "\n",
    "    text = \"\"\"\n",
    "    I was diagnosed in 2018 after the accident.\n",
    "    Symptoms have been there since childhood and got worse last winter.\n",
    "    I relapsed again this year after quitting meds two months ago.\n",
    "    Started therapy in June. Hospitalised three years ago.\n",
    "    Had another episode last month and during lockdown things escalated.\n",
    "    I struggled for six months before the diagnosis.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(extract_time_spans(text, nlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98e769-caa0-4c53-b671-6dbb30f02dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
