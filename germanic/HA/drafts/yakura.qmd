---
title: yakura replique
bibliography: germanic-ai.bib
#nocite: '@pethes_war_2006'
# tables:
#   - tbl_qa: {file: "qa.qmd", num: 1}
#   - tbl-summary: {file: "results.qmd", num: 2}

---

{{< include _vars.qmd >}}

## notes on replication study of: @yakura_empirical_2025
we started replicating the workflow presented in above study beginning with creating the target corpus. @yakura_empirical_2025 built corpora from transcribed youtube video audios and podcasts, referencing an research organisations registry (@registry_ror_2025) to collect videos from institutional educational youtube channels. we conducted data the same way restricted to german institutions. @yakura_empirical_2025 limited the target corpus to 4 years before the introduction of the GPT chat agent on 2022-11-31 up to 2024-05-31. this allows a timebased analysis of hypothesised appearance of AI-speech induced variances.

we tested the workflow until state of video transcribed using the youtube search API for finding the corresponding video channels, llama3.2 to match the correct channel within the search results, yt-dlp to download the video audio, ffmpeg library to convert to .wav and whisper AI to finally transcribe the audio. all worked well (automatic) with resulting two text from Mannheim University channel youtube contributions. we estimate an overal server runtime of about 10h to download and transcribe all audio to text of above categorized channels.
