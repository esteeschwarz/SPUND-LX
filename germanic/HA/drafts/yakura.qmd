---
title: yakura replique
bibliography: germanic-ai.bib
#nocite: '@pethes_war_2006'
# tables:
#   - tbl_qa: {file: "qa.qmd", num: 1}
#   - tbl-summary: {file: "results.qmd", num: 2}

---

{{< include _vars.qmd >}}

## notes on replication study of @yakura_empirical_2025
we started replicating the workflow presented in above study beginning with creating the target corpus. @yakura_empirical_2025 built corpora from transcribed youtube video audios and podcasts, referencing a research organisations registry (@registry_ror_2025) to collect videos from institutional educational youtube channels. we assemlbled data the same way restricted to german institutions. @yakura_empirical_2025 limited the target corpus to 4 years before the introduction of the GPT chat agent on 2022-11-31 up to 2024-05-31. this allowed a timebased analysis of hypothesised appearance of AI-speech induced variances.

we tested the workflow until state of video transcribed using the youtube search API for finding the corresponding video channels, llama3.2 to match the correct channel within the search results, yt-dlp to download the video audio, ffmpeg library to convert to PCM .wav and whisper AI to finally transcribe the audio. all worked well ([script](https://github.com/esteeschwarz/SPUND-LX/tree/main/germanic/HA/LLM-001.R)) with resulting two texts from Mannheim University channel youtube contributions. we estimate an overall server runtime of about 10h to download and transcribe to text all audio of above categorized channels.

## process on yakura replication
after starting with the same pipeline of building a corpus from youtube material, we decided for another alternative out of resource reasons. the current corpus which we will work on is created from german parliamental protocols, freely available (resource reason) here: @dip_dip_2026. Also we decided for google gemini since working with that model simply costs less than the openAI GPT variant.

for the beginning we created a subset of protocols from 2021-01-01 to 2021-07-31 which are 38 protocols. to get the model preferred vocabulary we prompted gemini to summarize each protocol in its own words with restricting to not using more than 5% of words from the original text and limited to 300 words/summary. See prompt text @sec-gemini-prompt. we postag the corpus and devise relative lemma frequencies to get the gemini keywords.

### gemini prompt {#sec-gemini-prompt}
```{r}
#| echo: false
#| warning: false

ptx<-readLines("../g-prompt01.txt")
print(ptx)
```
