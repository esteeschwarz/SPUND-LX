---
title: 'TOPIC #6'
output:
  html_document:
    df_print: paged
  html_notebook:
    df_print: paged
navbar:
  title: topic 6
  left:
  - text: index
    href: index.html
  - text: paper
    href: paper.html
  - text: slide
    href: "HA-slides.html"
    id: slides
  - text: doku
    href: _doku.nb.html
---
# PRE
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

replacemask snc: #replacemask#

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
plot(cars)
```

## cats
Add a new katze hund dreimal by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

# process

## preliminary
```{r script-14015,eval=T,echo=T,warning=FALSE}
#20240103(07.42)
###############################################################
### this script runs without local files, all data fetched from online sources.
###############################################################################
R.1<-"https://www.linguistics.ucsb.edu/research/santa-barbara-corpus"
Q.2<-"https://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/SBCorpus.zip"
library(utils)
library(stringi)
library(quanteda.textstats)
library(quanteda)
library(udpipe) # for pos tagging

local<-"~/boxHKW/21S/DH/local/SPUND/corpuslx"
udpipepath<-sprintf("%s/english-ewt-ud-2.5-191206.udpipe",local)
### if not yet, the model must be downloaded, comment in above line 

get.udp<-function(){
udpipe_download_model("english",model_dir = tempdir("md"))
mdf<-list.files(tempdir())
mdw<-grep(".udpipe",mdf)
mdfile<-paste0(tempdir(),"/",mdf[mdw])
md<-udpipe_load_model(mdfile)
}

### if the model is not on disk, it is downloaded
ifelse(exists("udpipepath"),md<-udpipe_load_model(udpipepath),md<-get.udp())
getwd()

### tempfile to store zip
sbctemp<-tempfile("SBCtemp.zip")
sbctempdir<-tempdir()
download.file(Q.2,sbctemp)
unzip(sbctemp,exdir = sbctempdir)

### load library for table processing
library(readr)
sbctrn<-paste0(sbctempdir,"/TRN/")
filestrn<-list.files(sbctrn)
trndf<-data.frame(scb=NA,id=NA,text=NA)
#k<-1
```

### read in files

```{r, echo=FALSE}
for(k in 1:length(filestrn)){
  #cat(k,"\n")
trntemp<-read_delim(paste0(sbctrn,filestrn[k]), 
                         delim = "\t", escape_double = FALSE, 
                         trim_ws = TRUE,col_names = c("id","spk","text"))

l1<-length(trntemp)
trntext<-trntemp[,l1]
colnames(trntext)<-"text"
trntemp.2<-data.frame(scb=k,id=1:length(trntext$text),text=trntext)
  
trndf<-rbind(trndf,trntemp.2)

}
```

#### which look like this

```{r show-trn-rawdata,eval=TRUE}
trn.doc.1<-readLines(paste0(sbctrn,filestrn[1]))
print(trn.doc.1[1:15])
```

### subsets

```{r,eval=FALSE,warning=F,echo=T}
trndf.2<-trndf[2:length(trndf$scb),]
trndf.2$lfd<-1:length(trndf.2$scb)
rownames(trndf.2)<-trndf.2$lfd
trndf$lfd<-1:length(trndf$scb)
m1<-grep("take|took|taken|taking",trndf$text) #take:415,tak:478 obs.
trn.take<-cbind(trndf[m1,],"concrete"=0,"light"=1)
m2<-grep("made|make|making",trndf$text) #take:415,tak:478 obs. #mak
trn.make.2<-cbind(trndf[m2,],"concrete"=0,"light"=1) #430
m3<-grep("give|gave|giving",trndf$text) #take:415,tak:478 obs.
trn.give<-cbind(trndf[m3,],"concrete"=0,"light"=1) #235
### wks., wonderful. now annotate for concrete/light use
```

### annotate for /make/

```{r,echo=T,warning=F,eval=FALSE}
######################################
### instances concrete vs. light
### Q.1: (Mehl 2021)
i.make.w<-c(concrete=68,light=321) #17% vs. 83% written ICE 
i.make.s<-c(concrete=96,light=353) #spoken ICE
i.take<-c(con=62,light=85) 
i.give<-c(con=52,light=167) 
###########################
trndf_sf<-trndf # saved created, load only annotations dataframe
dtemp<-tempfile()
download.file("https://github.com/esteeschwarz/SPUND-LX/raw/main/corpusLX/14015-HA/data/SBC.ann.df.RData",dtemp)
load(dtemp)
get.ann.x<-function(scb,ann.df){
  trndf.lm<-cbind(scb,ann.df)
}
trndf.lm<-get.ann.x(trndf.2,scb.ann.df)
m4<-trndf.lm$light==1&trndf.lm$alt=="make"
### sum light annotated
l.light<-sum(m4,na.rm = T)
### concrete annotated
l.conc<-sum(trndf.lm$light==0&trndf.lm$alt=="make",na.rm = T)
i.make.m<-c(concrete=l.conc,light=l.light)
### percentage
i.make.w[2]/(i.make.w[1]+i.make.w[2])
i.make.s[2]/(i.make.s[1]+i.make.s[2])
i.make.m[2]/(i.make.m[1]+i.make.m[2]) # 29 vs 71%
### wks.
### semantic alternates of concrete /make/ (p.14)
###
### B >
trndf<-trndf.lm
### search for semantic alternates
get.alt<-function(altregex,alt){
m1<-grep(altregex,trndf$text)
trn.temp<-cbind(trndf[m1,],alt=alt,light=0)
trn.alt<-rbind(trn.alt,trn.temp)
}
m1<-c("(generat(e|ing|ed))[^generator]","generate")
m2<-c("(construct(ing|ed))[^constructor]","construct")
m3<-c("(produc(e|ing|ed))[^producer]","produce")
m4<-c("(creat(e|ing|ed))[^creator]","create")
m5<-c("(buil(d|ding|t))[^builder]","build")
m1.m<-grep(m1[1],trndf$text)
trn.temp<-cbind(trndf[m1.m,],alt=m1[2],light=0)
trn.alt<-trn.temp
trn.alt<-get.alt(m2[1],m2[2])
trn.alt<-get.alt(m3[1],m3[2])
trn.alt<-get.alt(m4[1],m4[2])
trn.alt<-get.alt(m5[1],m5[2])

trndf.all<-trndf
#table(trn.alt$alt)
### B <
### B >
par(las=3)
alt.c.table<-table(trndf.all$alt[trndf.all$light==0])
#alt.c.table
### B <
chk<-trndf.lm$alt=="make"
trntable<-table(trndf.lm$alt[trndf.lm$light==0])
table(trndf.lm$alt)
```

### PoS tagging
#### tokenize
```{r tokenize,eval=F,echo=T,warning=FALSE}
### from here with preloaded df
load("~/boxHKW/21S/DH/local/SPUND/corpuslx/stefanowitsch/HA/data/trndf.lm.cpt.RData")
#save(trndf.lm,file = "~/boxHKW/21S/DH/local/SPUND/corpuslx/stefanowitsch/HA/data/trndf.lm.cpt.RData")

library(stringi)
df.build<-trndf.lm[trndf.lm$alt=="build",]
df.build$alt.true<-0
set<-trndf.lm
alt<-"manufacture"
alt.g<-"(manufactur(ing|e|ed))"
trndf.lm$verb<-NA
############################
get.coll<-function(set,verb,alt,alt.g){
    m<-set$alt==alt&set$light==0
    wm<-which(m)
    m2<-grepl(alt.g,set$text)
    sum(m)
    sum(m2)
    m2<-which(m2)
    head(set$text[m])
    head(set$text[m2])
    set$verb[m2]<-verb
    set$alt[m2]<-alt
    m.split<-tokens(set$text[wm],remove_numbers = T,remove_punct = T,remove_symbols = T,remove_separators = T,split_hyphens = T,include_docvars = T)
    m.split.g<-tokens(set$text[m2],remove_numbers = T,remove_punct = T,remove_symbols = T,remove_separators = T,split_hyphens = T,include_docvars = T)
    tok.clean<-function(x)gsub("[0-9@]","",x)
    m.split<-lapply(m.split, tok.clean)
    tok.clean<-function(x)gsub("[0-9@]","",x)
    m.split.g.c<-lapply(m.split.g, tok.clean)
    m.split.g<-m.split.g.c
    returnlist<-list(set=set,tokens=m.split,tokens.g=m.split.g)
    return(returnlist)
    return(df.split)
}
```

#### pos tag

```{r postag,eval=F,warning=FALSE,echo=T}
library(udpipe)
library(quanteda)
### get token df
split.take<-get.coll(trndf.lm,"take","take","(take|took|taken|taking)")
split.df<-split.take
### get postagged df from token df
get.noun.coll<-function(split.df){
make.freq<-"n.a."
an6<-"n.a."
an6.n<-"n.a."
tok.clean<-function(x)gsub("[0-9@]","",x)
  if(length(split.df$tokens)>0){
    m.split<-split.df$tokens
    m.split.c<-lapply(split.df$tokens.g, tok.clean)
    m.split.ct<-tokens(m.split.c)
  dfm.make.2<-m.split.ct%>%tokens_remove(stopwords("en"))%>%dfm()
  make.freq<-textstat_frequency(dfm.make.2)
### 
tna<-make.freq$feature
an3<-udpipe_annotate(md,x=tna,tagger = "default",parser = "none")
an6<-as.data.frame(an3)
an6.n<-an6$sentence[an6$upos=="NOUN"]
}
m.split.g<-split.df$tokens.g
m.split.g.c<-lapply(split.df$tokens.g, tok.clean)
m.split.g<-m.split.g.c
m.split.t<-tokens(m.split.g.c)
dfm.make.g<-m.split.t%>%tokens_remove(stopwords("en"))%>%dfm()
dfm.make.g
make.freq.g<-textstat_frequency(dfm.make.g)
tna.g<-make.freq.g$feature
an3.g<-udpipe_annotate(md,x=tna.g,tagger = "default",parser = "none")
an6.g<-as.data.frame(an3.g)
an6.n.g<-an6.g$sentence[an6.g$upos=="NOUN"]
if(length(split.df$tokens)==0){
 make.freq<-make.freq.g
 an6<-an6.g
 an6.n<-an6.n.g
}
returnlist<-list(set=split.df$set,freq=make.freq,ann=an6,nouns=an6.n,freq.g=make.freq.g,ann.g=an6.g,nouns.g=an6.n.g)
}
```
